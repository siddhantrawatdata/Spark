{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- booking_date: string (nullable = true)\n |-- booking_id: string (nullable = true)\n |-- car_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- end_time: string (nullable = true)\n |-- start_time: string (nullable = true)\n |-- status: string (nullable = true)\n |-- total_amount: double (nullable = true)\n\nroot\n |-- customer_id: string (nullable = true)\n |-- email: string (nullable = true)\n |-- name: string (nullable = true)\n |-- phone_number: string (nullable = true)\n |-- signup_date: string (nullable = true)\n |-- status: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "from pyspark.sql.functions import *\n",
    "import datetime as dt\n",
    "file_location_zoom_bookings = \"/FileStore/zoom_car_booking_data/\"\n",
    "file_location_zoom_customers = \"/FileStore/zoom_car_customer_data/\"\n",
    "file_type = \"json\"\n",
    "\n",
    "\n",
    "zoom_car_booking_data = spark.read.json(file_location_zoom_bookings)\n",
    "zoom_car_customer_data = spark.read.json(file_location_zoom_customers)\n",
    "\n",
    "zoom_car_booking_data.printSchema()\n",
    "zoom_car_customer_data.printSchema()\n",
    "\n",
    "# # The code to read json file for current date , the code is commented as we do not have a regulary scheduled pipeline\n",
    "# file_location_zoom_bookings = \"/FileStore/zoom_car_booking_data/\"\n",
    "# file_location_zoom_customers = \"/FileStore/zoom_car_customer_data/\"\n",
    "\n",
    "# current_dt = spark.sql(\"select current_date() as current_date\")\n",
    "# daily_file_path_zoom_bookings= file_location_zoom_bookings + \"zoom_car_bookings_\" + current_dt.collect()[0][0].strftime(\"%Y%m%d\") +\".json\"\n",
    "# daily_file_path_zoom_customers = file_location_zoom_customers + \"zoom_car_customers_\" + current_dt.collect()[0][0].strftime(\"%Y%m%d\") +\".json\"\n",
    "\n",
    "# zoom_car_booking_data = spark.read.json(daily_file_path_zoom_bookings)\n",
    "# zoom_car_customer_data = spark.read.json(daily_file_path_zoom_customers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- booking_date: string (nullable = true)\n |-- booking_id: string (nullable = true)\n |-- car_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- end_time: string (nullable = true)\n |-- start_time: string (nullable = true)\n |-- status: string (nullable = true)\n |-- total_amount: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Remove records with null values in critical fields (booking_id,customer_id, car_id, booking_date).\n",
    "zoom_car_cleaned_booking_data = zoom_car_booking_data.dropna(subset=[\"booking_id\",\"customer_id\",\"car_id\",\"booking_date\"])\n",
    "zoom_car_cleaned_booking_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f66379-6f7f-42ec-8e82-d0e0926a1721",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|valid_status|\n+------------+\n|   completed|\n|     pending|\n|    inactive|\n|      active|\n|   cancelled|\n+------------+\n\n+--------+----------+------------+----------+------+-----------+------+------------+------------+\n|end_time|start_time|booking_date|booking_id|car_id|customer_id|status|total_amount|valid_status|\n+--------+----------+------------+----------+------+-----------+------+------------+------------+\n+--------+----------+------------+----------+------+-----------+------+------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#validate the date formats \n",
    "zoom_car_date_refactored = zoom_car_cleaned_booking_data.select(col('end_time').cast('timestamp')\\\n",
    "    ,col('start_time').cast('timestamp')\\\n",
    "        ,'booking_date'\\\n",
    "            ,'booking_id'\\\n",
    "                ,'car_id'\\\n",
    "                    ,'customer_id'\\\n",
    "                        ,'status'\\\n",
    "                            ,'total_amount')\n",
    "\n",
    "\n",
    "# Find if all the status are as per the defined status\n",
    "# There can be multiple approaches but the one i have taken is to create a small daaframe of all valid status and doing a left join from the bookings data to smaller dataset and filter out records which do not have a match \n",
    "\n",
    "data = [{'valid_status':'completed'},\n",
    "        {'valid_status':'pending'},\n",
    "        {'valid_status':'inactive'},\n",
    "        {'valid_status':'active'},\n",
    "        {'valid_status':'cancelled'}\n",
    "        ]\n",
    "\n",
    "defined_status = spark.createDataFrame(data)\n",
    "defined_status.show(10)\n",
    "\n",
    "bookings_joined_defined_status = zoom_car_date_refactored.join(defined_status, \\\n",
    "    on=zoom_car_date_refactored['status']==defined_status['valid_status']\\\n",
    "    ,how='left')\\\n",
    "        .filter(col('valid_status').isNull())\n",
    "\n",
    "bookings_joined_defined_status.show(10)\n",
    "\n",
    "# if the bookings_joined_defined_status returns any records then we can put it in an error file \n",
    "bookings_joined_defined_status.write.mode(\"overwrite\").csv(\"/FileStore/error_file_booking_data.csv\",header=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db9631f6-bb4a-42ca-8a3c-0d48af932331",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "--load cleaned data into staging bookings delta table \n",
    "--create the schema if not eixsts \n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS dev_databricks_projects.zoom_data;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0402547f-0761-46d5-8267-e73731308bbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load cleaned data into a staging table\n",
    "\n",
    "bookings_joined_defined_status = zoom_car_date_refactored.join(defined_status, \\\n",
    "    on=zoom_car_date_refactored['status']==defined_status['valid_status']\\\n",
    "    ,how='left')\\\n",
    "        .filter(col('valid_status').isNotNull())\n",
    "\n",
    "bookings_joined_defined_status.write.mode(\"overwrite\").saveAsTable(\"dev_databricks_projects.zoom_data.staging_booking_data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5e32b4a-3711-43a3-ad90-d1b61ea929d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+---------------+\n|  end_date|end_timestamp|start_date|start_timestamp|\n+----------+-------------+----------+---------------+\n|2024-08-05|     05:41:00|2024-08-05|       05:40:00|\n|2024-08-05|     05:41:00|2024-08-05|       05:40:00|\n|2024-08-05|     12:23:00|2024-08-05|       12:20:00|\n|2024-08-05|     12:56:00|2024-08-05|       12:50:00|\n|2024-08-05|     04:12:00|2024-08-05|       04:10:00|\n|2024-08-05|     12:51:00|2024-08-05|       12:50:00|\n|2024-08-05|     04:13:00|2024-08-05|       04:10:00|\n|2024-08-05|     02:15:00|2024-08-05|       02:10:00|\n|2024-08-05|     12:13:00|2024-08-05|       12:10:00|\n|2024-08-05|     04:16:00|2024-08-05|       04:10:00|\n+----------+-------------+----------+---------------+\nonly showing top 10 rows\n\n+----------------+\n|booking_duration|\n+----------------+\n|            15.0|\n|             3.0|\n|             6.0|\n|             3.0|\n|             5.0|\n|             1.0|\n|             5.0|\n|             3.0|\n|             1.0|\n|             5.0|\n+----------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# application of transformations\n",
    "#Parse start and end time to separate date time columns\n",
    "    \n",
    "\n",
    "bookings_joined_defined_status_new_columns = bookings_joined_defined_status.withColumn('start_date',to_date(col('start_time')))\\\n",
    "    .withColumn('start_timestamp',date_format(col('start_time'),'hh:mm:ss'))\\\n",
    "        .withColumn('end_date',to_date(col('end_time')))\\\n",
    "            .withColumn('end_timestamp',date_format(col('end_time'),'hh:mm:ss'))                \n",
    "\n",
    "bookings_joined_defined_status_new_columns.select('end_date','end_timestamp','start_date','start_timestamp').show(10)\n",
    "\n",
    "# calculate total duration of each booking\n",
    "\n",
    "total_duration_of_booking = bookings_joined_defined_status_new_columns.withColumn('booking_duration',(unix_timestamp('end_time')-unix_timestamp('start_time'))/60)\n",
    "\n",
    "total_duration_of_booking.select('booking_duration').show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f40250-6045-47c3-9093-b3f0ea181eb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3794683855335015,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Zoom Car Booking Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
