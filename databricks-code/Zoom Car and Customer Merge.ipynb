{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "791ffdd5-6d7c-4c01-9884-ed8643cb2f96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- end_time: timestamp (nullable = true)\n |-- start_time: timestamp (nullable = true)\n |-- booking_date: string (nullable = true)\n |-- booking_id: string (nullable = true)\n |-- car_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- status: string (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- valid_status: string (nullable = true)\n\nroot\n |-- customer_id: string (nullable = true)\n |-- email: string (nullable = true)\n |-- name: string (nullable = true)\n |-- phone_number: string (nullable = true)\n |-- signup_date: string (nullable = true)\n |-- status: string (nullable = true)\n |-- is_email_valid: string (nullable = true)\n |-- def_status: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Read the staged data and perform the merge operations \n",
    "\n",
    "stg_booking_data = spark.sql(\"select * from dev_databricks_projects.zoom_data.staging_booking_data\")\n",
    "stg_customer_data = spark.sql(\"select * from dev_databricks_projects.zoom_data.staging_customers_data\")\n",
    "\n",
    "stg_booking_data.printSchema()\n",
    "stg_customer_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc09e331-cb45-4cc8-b8d3-ddaa57b7cb8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "create table if not exists dev_databricks_projects.zoom_data.customer_data_scd1\n",
    "(\n",
    "id bigint GENERATED ALWAYS AS IDENTITY,\n",
    "customer_id  string ,\n",
    "email string ,\n",
    "name string , \n",
    "phone_number string, \n",
    "signup_date date,\n",
    "status string ,\n",
    "is_email_valid string, \n",
    "def_status string ,\n",
    "primary key (id)\n",
    ");\n",
    "\n",
    "create table if not exists dev_databricks_projects.zoom_data.booking_data_scd1\n",
    "(\n",
    "id bigint GENERATED ALWAYS AS IDENTITY,\n",
    "end_time timestamp,\n",
    "start_time timestamp,\n",
    "booking_date string,\n",
    "booking_id string,\n",
    "car_id string,\n",
    "customer_id string,\n",
    "status string,\n",
    "total_amount double,\n",
    "valid_status string,\n",
    "primary key (id)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb375f80-deeb-46e3-a19a-9fcfb9600a45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "# Apply the merge operations on the bookings and customer datasets \n",
    "\n",
    "#booking dataset\n",
    "# First check if the target table exists or not. If not them directly upload stage data as it is first load\n",
    "booking_target_table = \"dev_databricks_projects.zoom_data.booking_data_scd1\"\n",
    "customer_target_table = \"dev_databricks_projects.zoom_data.customer_data_scd1\"\n",
    "\n",
    "if not spark.catalog.tableExists(booking_target_table):\n",
    "  stg_booking_data.write.format(\"delta\").saveAsTable(booking_target_table)\n",
    "else:\n",
    "  #Perform the merge related operations\n",
    "  target_table = DeltaTable.forName(spark, booking_target_table)\n",
    "  merge_condition = \"source.booking_id = target.booking_id\"\n",
    "  stg_cancelled_booking_data = stg_booking_data.filter(col('status')=='cancelled')\n",
    "\n",
    "\n",
    "   # Execute merge operation for updated and new records\n",
    "\n",
    "  target_table.alias('target').merge(stg_booking_data.alias('source'),merge_condition)\\\n",
    "    .whenMatchedUpdate(set={\n",
    "          'end_time' : 'source.end_time',\n",
    "          'start_time' : 'source.start_time',\n",
    "          'booking_date' :'source.booking_date',\n",
    "          'booking_id' :'source.booking_id',\n",
    "          'car_id' :'source.car_id',\n",
    "          'customer_id': 'source.customer_id',\n",
    "          'status' :'source.status',\n",
    "          'total_amount': 'source.total_amount',\n",
    "          'valid_status' :'source.valid_status'\n",
    "      })\\\n",
    "        .whenNotMatchedInsert(values={\n",
    "          'end_time' : 'source.end_time',\n",
    "          'start_time' : 'source.start_time',\n",
    "          'booking_date' :'source.booking_date',\n",
    "          'booking_id' :'source.booking_id',\n",
    "          'car_id' :'source.car_id',\n",
    "          'customer_id': 'source.customer_id',\n",
    "          'status' :'source.status',\n",
    "          'total_amount': 'source.total_amount',\n",
    "          'valid_status' :'source.valid_status'\n",
    "        })\\\n",
    "          .execute()\n",
    "# Delete cancelled records\n",
    "  target_table.alias('target').merge(stg_cancelled_booking_data.alias('source'),merge_condition)\\\n",
    "    .whenMatchedDelete()\\\n",
    "      .execute()\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d77940-edf8-496d-ba5a-f4b1e6ce5fee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customer dataset \n",
    "\n",
    "customer_target_table = \"dev_databricks_projects.zoom_data.customer_data_scd1\"\n",
    "\n",
    "#check if the customer table exists\n",
    "if not spark.catalog.tableExists(customer_target_table):\n",
    "    stg_customer_data.write.format(\"delta\").saveAsTable(customer_target_table)\n",
    "else:\n",
    "    #merge condition to update and insert records\n",
    "    target_table = DeltaTable.forName(spark, customer_target_table)\n",
    "    merge_condition = \"source.customer_id = target.customer_id\"\n",
    "    target_table.alias('target').merge(stg_customer_data.alias('source'),merge_condition)\\\n",
    "        .whenMatchedUpdate(set={\n",
    "            'email' : 'source.email',\n",
    "            'name' :'source.name',\n",
    "            'phone_number' :'source.phone_number',\n",
    "            'signup_date' :'source.signup_date',\n",
    "            'status' :'source.status',\n",
    "            'is_email_valid' :'source.is_email_valid',\n",
    "            'def_status' :'source.def_status'\n",
    "\n",
    "        })\\\n",
    "            .whenNotMatchedInsert(values={\n",
    "                'email' : 'source.email',\n",
    "                'name' :'source.name',\n",
    "                'phone_number' :'source.phone_number',\n",
    "                'signup_date' :'source.signup_date',\n",
    "                'status' :'source.status',\n",
    "                'is_email_valid' :'source.is_email_valid',\n",
    "                'def_status' :'source.def_status'\n",
    "            })\\\n",
    "                .execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f9ea704-fbb2-4df3-a943-e4f5c8bc9d45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2468218227321321,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Zoom Car and Customer Merge",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
